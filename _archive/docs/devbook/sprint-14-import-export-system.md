# Sprint 14 - Syst√®me Import/Export G√©n√©rique

## üìã R√©sum√© Ex√©cutif

**Statut**: üöß **EN COURS**  
**Objectif**: Impl√©menter syst√®me complet import/export selon roadmaps CSV 1-5  
**Foundation**: Service export fonctionnel, service import partiel  
**Cible**: Service g√©n√©rique r√©utilisable toutes entit√©s

## üéØ Objectifs Sprint 14

### Phase 1 - Service Import G√©n√©rique ‚úÖ PLANIFI√â
- **App d√©di√©e** : `apps/imports` avec mod√®les complets
- **Pipeline 5 √©tapes** : upload ‚Üí preview ‚Üí mapping ‚Üí dry-run ‚Üí execute
- **S√©curit√©** : streaming, hash SHA-256, anti-injection CSV
- **Mod√®les** : `ImportJob`, `ImportJobRow`, `ImportMapping`

### Phase 2 - UI/UX Compl√®te üéØ CIBLE
- **Modal g√©n√©rique** r√©utilisable toutes entit√©s
- **√âcrans mapping** avec drag & drop
- **Pr√©visualisation** temps r√©el avec transformations
- **Rapports** t√©l√©chargeables (erreurs.csv, warnings.csv)

### Phase 3 - Int√©gration Pages üéØ CIBLE
- **Boutons Import/Export** sur toutes pages listes
- **Adapters entit√©s** configurables
- **Tests E2E** complets (Playwright)

## üèóÔ∏è Architecture Cible

### App Imports Structure
```
apps/imports/
‚îú‚îÄ‚îÄ models.py              # ImportJob, ImportJobRow, ImportMapping
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ upload_service.py   # CSV_1: Upload & Preview
‚îÇ   ‚îú‚îÄ‚îÄ mapping_service.py  # CSV_2: Mapping & Transformations
‚îÇ   ‚îú‚îÄ‚îÄ dryrun_service.py   # CSV_3: Validation & FK Lookup
‚îÇ   ‚îú‚îÄ‚îÄ execute_service.py  # CSV_4: Upsert Idempotent
‚îÇ   ‚îî‚îÄ‚îÄ report_service.py   # CSV_5: Rapports & Observabilit√©
‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Adapter g√©n√©rique
‚îÇ   ‚îú‚îÄ‚îÄ grape_variety.py   # Adapter c√©pages
‚îÇ   ‚îú‚îÄ‚îÄ parcelle.py        # Adapter parcelles
‚îÇ   ‚îî‚îÄ‚îÄ unite.py           # Adapter unit√©s
‚îú‚îÄ‚îÄ views.py               # Endpoints REST API
‚îú‚îÄ‚îÄ urls.py                # Routes /import/*
‚îî‚îÄ‚îÄ templates/imports/     # UI g√©n√©rique
```

### Mod√®les Cibles
```python
class ImportJob(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4)
    organization = models.ForeignKey(Organization)
    entity = models.CharField(max_length=50)  # 'grape_variety', 'parcelle'
    filename = models.CharField(max_length=255)
    size_bytes = models.PositiveIntegerField()
    sha256 = models.CharField(max_length=64)
    status = models.CharField(choices=STATUS_CHOICES, default='uploaded')
    total_rows = models.PositiveIntegerField(null=True)
    created_by = models.ForeignKey(User)
    started_at = models.DateTimeField(auto_now_add=True)
    ended_at = models.DateTimeField(null=True)
    
    # M√©triques
    inserted_count = models.PositiveIntegerField(default=0)
    updated_count = models.PositiveIntegerField(default=0)
    skipped_count = models.PositiveIntegerField(default=0)
    error_count = models.PositiveIntegerField(default=0)
    warning_count = models.PositiveIntegerField(default=0)

class ImportJobRow(models.Model):
    job = models.ForeignKey(ImportJob, related_name='rows')
    row_index = models.PositiveIntegerField()
    status = models.CharField(choices=['ok', 'warning', 'error'])
    field = models.CharField(max_length=100, blank=True)
    message = models.TextField()
    suggestion = models.TextField(blank=True)
    raw_data = models.JSONField()  # Donn√©es ligne originale
    processed_data = models.JSONField(null=True)  # Apr√®s transformations

class ImportMapping(models.Model):
    job = models.ForeignKey(ImportJob, related_name='mappings')
    csv_column = models.CharField(max_length=100)
    entity_field = models.CharField(max_length=100)
    transforms = models.JSONField(default=list)  # ['trim', 'unaccent']
    options = models.JSONField(default=dict)
```

## üîß Services D√©taill√©s

### UploadService (CSV_1)
```python
class UploadService:
    """Ingestion s√©curis√©e & Pr√©visualisation"""
    
    def upload_file(self, file, entity, organization, user):
        # Validation s√©curit√©
        self._validate_file_security(file)
        
        # Stockage temporaire
        job = self._create_import_job(file, entity, organization, user)
        file_path = self._store_temporary_file(file, job)
        
        # Hash SHA-256
        job.sha256 = self._calculate_sha256(file_path)
        job.save()
        
        return job
    
    def preview_file(self, job_id, rows=10, sheet=0):
        # D√©tection encodage/s√©parateur
        detected = self._detect_file_format(job.file_path)
        
        # Lecture streaming s√©curis√©e
        sample_data = self._read_sample_data(job.file_path, rows, detected)
        
        # Anti-injection CSV
        sample_data = self._neutralize_csv_injection(sample_data)
        
        return {
            'header': sample_data[0] if detected['has_header'] else [],
            'sample': sample_data[1:] if detected['has_header'] else sample_data,
            'detected': detected,
            'warnings': self._generate_warnings(detected)
        }
```

### MappingService (CSV_2)
```python
class MappingService:
    """Mapping des champs & Transformations"""
    
    def get_entity_schema(self, entity):
        adapter = self._get_adapter(entity)
        return adapter.get_schema()
    
    def auto_map_columns(self, job_id, csv_columns):
        schema = self.get_entity_schema(job.entity)
        mapping = {}
        
        for csv_col in csv_columns:
            # Recherche par synonymes
            field = self._find_field_by_synonyms(csv_col, schema['synonyms'])
            if field:
                mapping[csv_col] = {
                    'field': field,
                    'transforms': schema['transforms_defaults'].get(field, []),
                    'confidence': self._calculate_confidence(csv_col, field)
                }
        
        return mapping
    
    def save_mapping(self, job_id, mapping):
        # Validation mapping
        self._validate_mapping(job.entity, mapping)
        
        # Sauvegarde
        ImportMapping.objects.filter(job_id=job_id).delete()
        for csv_col, config in mapping.items():
            ImportMapping.objects.create(
                job_id=job_id,
                csv_column=csv_col,
                entity_field=config['field'],
                transforms=config['transforms'],
                options=config.get('options', {})
            )
```

## üé® UI/UX G√©n√©rique

### Modal Import R√©utilisable
```html
<!-- templates/imports/modal_import.html -->
<div class="modal fade" id="importModal" tabindex="-1">
    <div class="modal-dialog modal-xl">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">
                    <i class="bi bi-upload me-2"></i>
                    Importer {{ entity_display_name }}
                </h5>
            </div>
            <div class="modal-body">
                <!-- √âtapes navigation -->
                <div class="import-steps mb-4">
                    <div class="step active" data-step="upload">1. Upload</div>
                    <div class="step" data-step="preview">2. Aper√ßu</div>
                    <div class="step" data-step="mapping">3. Mapping</div>
                    <div class="step" data-step="dryrun">4. Validation</div>
                    <div class="step" data-step="execute">5. Import</div>
                </div>
                
                <!-- Contenu dynamique par √©tape -->
                <div id="step-content">
                    <!-- Charg√© via AJAX selon √©tape -->
                </div>
            </div>
        </div>
    </div>
</div>
```

### JavaScript G√©n√©rique
```javascript
// static/js/import-modal.js
class ImportModal {
    constructor(entity, entityDisplayName) {
        this.entity = entity;
        this.entityDisplayName = entityDisplayName;
        this.currentStep = 'upload';
        this.jobId = null;
    }
    
    open() {
        $('#importModal').modal('show');
        this.loadStep('upload');
    }
    
    async loadStep(step) {
        const response = await fetch(`/import/ui/${step}/`, {
            method: 'GET',
            headers: {
                'X-Entity': this.entity,
                'X-Job-Id': this.jobId || ''
            }
        });
        
        const html = await response.text();
        document.getElementById('step-content').innerHTML = html;
        this.updateStepNavigation(step);
    }
    
    async uploadFile(formData) {
        const response = await fetch(`/import/${this.entity}/upload/`, {
            method: 'POST',
            body: formData,
            headers: {
                'X-CSRFToken': getCookie('csrftoken')
            }
        });
        
        const result = await response.json();
        this.jobId = result.job_id;
        this.loadStep('preview');
    }
}
```

## üìä Int√©gration Pages Listes

### Boutons Import/Export
```html
<!-- templates/referentiels/cepage_list.html -->
<div class="d-flex justify-content-between align-items-center mb-4">
    <h1>
        <i class="bi bi-flower1 me-2 text-success"></i>C√©pages
    </h1>
    <div>
        <!-- Boutons Import/Export -->
        <div class="btn-group me-2">
            <button type="button" class="btn btn-outline-primary" 
                    onclick="openImportModal('grape_variety', 'C√©pages')">
                <i class="bi bi-upload"></i> Importer
            </button>
            <button type="button" class="btn btn-outline-secondary"
                    onclick="openExportDialog('cepages')">
                <i class="bi bi-download"></i> Exporter
            </button>
        </div>
        
        <!-- Boutons existants -->
        <a href="{% url 'referentiels:home' %}" class="btn btn-outline-secondary me-2">
            <i class="bi bi-arrow-left"></i> R√©f√©rentiels
        </a>
        {% if user.get_active_membership.can_edit_data %}
            <a href="{% url 'referentiels:cepage_create' %}" class="btn btn-primary">
                <i class="bi bi-plus"></i> Nouveau c√©page
            </a>
        {% endif %}
    </div>
</div>
```

## üîí S√©curit√© & Performance

### Anti-Injection CSV
```python
def neutralize_csv_injection(value):
    """Neutralise les formules CSV dangereuses"""
    if isinstance(value, str) and value.startswith(('=', '+', '-', '@', '\t')):
        return f"'{value}"
    return value
```

### Streaming Upload
```python
def handle_large_file_upload(file, max_size=10*1024*1024):
    """Upload streaming pour fichiers volumineux"""
    if file.size > max_size:
        raise ValidationError(f"Fichier trop volumineux: {file.size} > {max_size}")
    
    hasher = hashlib.sha256()
    total_size = 0
    
    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        for chunk in file.chunks(chunk_size=64*1024):
            temp_file.write(chunk)
            hasher.update(chunk)
            total_size += len(chunk)
            
            if total_size > max_size:
                os.unlink(temp_file.name)
                raise ValidationError("Fichier trop volumineux")
    
    return temp_file.name, hasher.hexdigest()
```

## üìà M√©triques & Observabilit√©

### M√©triques Prometheus
```python
from prometheus_client import Counter, Histogram, Gauge

# M√©triques import
import_duration = Histogram('import_duration_seconds', 'Dur√©e import', ['entity', 'stage'])
import_rows_total = Counter('import_rows_total', 'Lignes import√©es', ['entity', 'status'])
import_errors_total = Counter('import_errors_total', 'Erreurs import', ['entity', 'error_type'])
lookup_ambiguous_total = Counter('lookup_ambiguous_total', 'Lookups ambigus', ['entity', 'field'])

# M√©triques export
export_duration = Histogram('export_duration_seconds', 'Dur√©e export', ['entity'])
export_rows_total = Counter('export_rows_total', 'Lignes export√©es', ['entity'])
```

## ‚úÖ Plan d'Impl√©mentation

### √âtape 1 - Foundation (Aujourd'hui)
- [x] **Audit complet** CSV 1-5 vs existant
- [x] **Documentation** architecture cible
- [ ] **App imports** : cr√©ation structure
- [ ] **Mod√®les** : ImportJob, ImportJobRow, ImportMapping

### √âtape 2 - Services Core
- [ ] **UploadService** : upload s√©curis√© + preview
- [ ] **MappingService** : auto-mapping + transformations
- [ ] **DryRunService** : validation + FK lookup
- [ ] **ExecuteService** : upsert idempotent

### √âtape 3 - UI/UX
- [ ] **Modal g√©n√©rique** r√©utilisable
- [ ] **√âcrans mapping** interactifs
- [ ] **Rapports** t√©l√©chargeables
- [ ] **JavaScript** g√©n√©rique

### √âtape 4 - Int√©gration
- [ ] **Boutons** sur toutes pages listes
- [ ] **Adapters** pour chaque entit√©
- [ ] **Tests E2E** complets

### √âtape 5 - Production
- [ ] **M√©triques** Prometheus
- [ ] **Quotas/rate-limit**
- [ ] **Runbook** op√©rationnel

## üéâ Impact Attendu

### Utilisateurs Finaux
- **Import convivial** : 5 √©tapes guid√©es avec pr√©visualisation
- **S√©curit√©** : validation compl√®te avant import effectif
- **Flexibilit√©** : mapping personnalisable, transformations
- **Feedback** : rapports d√©taill√©s, suggestions d'am√©lioration

### D√©veloppeurs
- **R√©utilisabilit√©** : service g√©n√©rique pour toutes entit√©s
- **Extensibilit√©** : adapters configurables
- **Maintenabilit√©** : architecture modulaire
- **Observabilit√©** : m√©triques et logs structur√©s

### Op√©rations
- **Monitoring** : dashboards temps r√©el
- **S√©curit√©** : quotas, rate-limit, audit trail
- **Performance** : streaming, cache, index optimis√©s
- **Fiabilit√©** : transactions, idempotence, reprise

---
*Sprint 14 - Syst√®me Import/Export G√©n√©rique - 2025-09-22*
